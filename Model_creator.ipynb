{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer, MaxAbsScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks.callbacks import Callback\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDf():\n",
    "    df = pd.read_csv('train.csv')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=['resp_1','resp_2','resp_3','resp_4','ts_id'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJumper(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global t\n",
    "        t = time() - t\n",
    "        if(t > 2.16e4):\n",
    "            error = True\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTVT_split(split):\n",
    "    df = getDf()\n",
    "    y = np.where(df['resp'] > 0,1,0).reshape(len(df),1)\n",
    "    x = df.values\n",
    "    \n",
    "    x_train, x_test = train_test_split(x,train_size=split,random_state=5)\n",
    "\n",
    "    y_train, y_test = train_test_split(y,train_size=split,random_state=5)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitter(gen,memb):\n",
    "    split = round(int(np.array2string(gen[:15],separator='')[1:-1],2)/10**5 + 0.5,5)\n",
    "    hid_layers = 21\n",
    "    act_in = act[int(int(np.array2string(gen[15:22],separator='')[1:-1],2)/11)]\n",
    "    nn_in = int(np.array2string(gen[22:29],separator='')[1:-1],2) + 1\n",
    "    act_out = act[int(int(np.array2string(gen[29:36],separator='')[1:-1],2)/11)]\n",
    "    \n",
    "    nn_hid = np.zeros(21).astype('int')\n",
    "    for i,j in zip(range(36,183,7),range(21)):\n",
    "        nn_hid[j] = int(np.array2string(gen[i:i+7],separator='')[1:-1],2)\n",
    "        \n",
    "    act_hid = np.zeros(21).astype('str')\n",
    "    for i,j in zip(range(183,330,7),range(21)):\n",
    "        act_hid[j] = act[int(int(np.array2string(gen[i:i+7],separator='')[1:-1],2)/11)]\n",
    "           \n",
    "    sc_each = list()\n",
    "    for i,j in zip(range(330,850,4),range(130)):\n",
    "        sc = int(np.array2string(gen[i:i+4],separator='')[1:-1],2)\n",
    "        if sc == 0:\n",
    "            scalerX = QuantileTransformer(output_distribution='normal',random_state=5)\n",
    "        elif sc == 1:\n",
    "            scalerX = QuantileTransformer(random_state=5)\n",
    "        elif sc == 2:\n",
    "            scalerX = MinMaxScaler()\n",
    "        elif sc == 3:\n",
    "            scalerX = StandardScaler()\n",
    "        elif sc == 4:\n",
    "            scalerX = StandardScaler(with_mean=True,with_std=False)\n",
    "        elif sc == 5:\n",
    "            scalerX = StandardScaler(with_mean=False,with_std=True)\n",
    "        elif sc == 6:\n",
    "            scalerX = StandardScaler(with_mean=False,with_std=False)\n",
    "        elif sc == 7:\n",
    "            scalerX = RobustScaler()\n",
    "        elif sc == 8:\n",
    "            scalerX = RobustScaler(with_centering=False,with_scaling=True)\n",
    "        elif sc == 9:\n",
    "            scalerX = RobustScaler(with_centering=True,with_scaling=False)\n",
    "        elif sc == 10:\n",
    "            scalerX = RobustScaler(with_centering=False,with_scaling=False)\n",
    "        elif sc == 11:\n",
    "            scalerX = PowerTransformer()\n",
    "        elif sc == 12:\n",
    "            scalerX = \"no\"\n",
    "        elif sc == 13:\n",
    "            scalerX = PowerTransformer(standardize=False)\n",
    "        elif sc == 14:\n",
    "            scalerX = MinMaxScaler(feature_range=(-1,1))\n",
    "        elif sc == 15:\n",
    "            scalerX = MaxAbsScaler()\n",
    "        sc_each.append(scalerX)\n",
    "        \n",
    "    ls = losses[int(int(np.array2string(gen[850:857],separator='')[1:-1],2)/10)]\n",
    "    opt = opts[int(np.array2string(gen[857:860],separator='')[1:-1],2)]\n",
    "    \n",
    "    if opt == 'adamT':\n",
    "        opt = optimizers.Adam(amsgrad=True)\n",
    "    \n",
    "    print('Member '+str(memb)+': '+'Loading data...',end='\\r',flush=True)\n",
    "    x_train, x_test, y_train, y_test = getTVT_split(split)\n",
    "    \n",
    "\n",
    "    for i in range(130):\n",
    "        print('Member '+str(memb)+': '+'Scaling '+str(i)+'...',end='\\r',flush=True)\n",
    "        if(sc_each[i]!=\"no\"):\n",
    "            x_train[:,i+3:i+4] = sc_each[i].fit_transform(x_train[:,i+3:i+4])\n",
    "            x_test[:,i+3:i+4] = sc_each[i].transform(x_test[:,i+3:i+4])      \n",
    "    \n",
    "    model = Sequential()\n",
    "    if act_in == '0':\n",
    "        model.add(Dense(nn_in,input_dim=(130)))\n",
    "    else:\n",
    "        model.add(Dense(nn_in,input_dim=(130),activation=act_in))\n",
    "\n",
    "    for i in range(21):\n",
    "        if nn_hid[i] == 0:\n",
    "            continue\n",
    "        elif act_hid[i] == '0':\n",
    "            model.add(Dense(nn_hid[i]))\n",
    "        else:\n",
    "            model.add(Dense(nn_hid[i],activation=act_hid[i]))\n",
    "\n",
    "    if act_out == '0':\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    else:\n",
    "        model.add(Dense(y_train.shape[1],activation=act_out))\n",
    "\n",
    "    model.compile(loss=ls,optimizer=opt)\n",
    "    \n",
    "    jumper = CustomJumper()\n",
    "    eps = int(np.array2string(gen[860:865],separator='')[1:-1],2) + 1\n",
    "    batch = int(np.array2string(gen[865:875],separator='')[1:-1],2) + 1\n",
    "    print('Member '+str(memb)+': '+'Fitting model...',end='\\r',flush=True)\n",
    "    error = False\n",
    "    t = time()\n",
    "    model.fit(x_train[:,3:],y_train,epochs=eps,batch_size=batch,verbose=0,callbacks=[jumper])\n",
    "    \n",
    "    if(error):\n",
    "        return 0\n",
    "    \n",
    "    print('Member '+str(memb)+': '+'Calculating LB...',end='\\r',flush=True)\n",
    "    results = model.predict_classes(x_test[:,3:])\n",
    "    \n",
    "    if ((np.count_nonzero(np.isnan(results)) > 0) or (np.count_nonzero(np.isinf(results)) > 0)):\n",
    "        return 0\n",
    "    \n",
    "    LB_array = np.concatenate((x_test[:,:1],x_test[:,1:2]*x_test[:,2:3]*results),axis=1)\n",
    "    K = (250/len(np.unique(LB_array[:,:1],axis=0)))**(1/2)\n",
    "    LB_data = [np.sum(LB_array[:,1:][np.nonzero(LB_array[:,:1]==date)]) for date in np.unique(LB_array[:,:1])]\n",
    "    t = np.sum(LB_data)/(np.sum(np.square(LB_data))**(1/2)) * K\n",
    "    if(math.isnan(t)):\n",
    "        t = 0\n",
    "    LB1 = t*np.sum(LB_data)\n",
    "    \n",
    "    LB_array = np.concatenate((x_test[:,:1],x_test[:,1:2]*x_test[:,2:3]*y_test),axis=1)\n",
    "    K = (250/len(np.unique(LB_array[:,:1],axis=0)))**(1/2)\n",
    "    LB_data = [np.sum(LB_array[:,1:][np.nonzero(LB_array[:,:1]==date)]) for date in np.unique(LB_array[:,:1])]\n",
    "    t = np.sum(LB_data)/(np.sum(np.square(LB_data))**(1/2)) * K\n",
    "    if(math.isnan(t)):\n",
    "        t = 0\n",
    "    LB2 = t*np.sum(LB_data)\n",
    "    \n",
    "    if (LB2==0):\n",
    "        return 0\n",
    "    \n",
    "    return LB1/LB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = ['0','linear','elu','selu','relu','sigmoid','hard_sigmoid','tanh','softmax','softplus','softsign','exponential']\n",
    "losses = ['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error','mean_squared_logarithmic_error','squared_hinge','hinge','categorical_hinge','logcosh','huber_loss','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity']\n",
    "opts = ['sgd','rmsprop','adagrad','adadelta','adam','adamT','adamax','nadam']\n",
    "n_gen = 20\n",
    "adn = 875\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = np.random\n",
    "rd.seed(5)\n",
    "\n",
    "pop = list()\n",
    "for i in range(20):\n",
    "    gen = rd.randint(0,2,adn,'int')\n",
    "    pop.append(gen)\n",
    "pop = np.array(pop)\n",
    "mez_pop = np.zeros(adn,'int').reshape(1,adn)\n",
    "mez_fit = np.zeros(1,'int').reshape(1,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tot_pop = pickle.load(open('Generations/pop_'+str(17)+'.pkl','rb'))\n",
    "tot_fit = pickle.load(open('Generations/fit_'+str(17)+'.pkl','rb'))\n",
    "\n",
    "mez_pop = tot_pop[tot_fit[:,0].argsort()][-int(len(pop)/2):]\n",
    "mez_fit = tot_fit[tot_fit[:,0].argsort()][-int(len(pop)/2):]\n",
    "print('Best result:'+str(tot_fit[tot_fit[:,0].argsort()][-1:]))\n",
    "n_pop = list()\n",
    "for i in range(len(pop)):\n",
    "    p1 = rd.randint(0,int(len(pop)/2))\n",
    "    p2 = rd.randint(0,int(len(pop)/2))\n",
    "    h = rd.randint(0,2,adn,'int')\n",
    "    h = h.astype(bool)\n",
    "    p1 = mez_pop[p1]\n",
    "    p2 = mez_pop[p2]\n",
    "    p1 = p1*h\n",
    "    p2 = p2*np.invert(h)\n",
    "    h = p1+p2\n",
    "\n",
    "    mut = rd.rand(adn)\n",
    "    mut = mut < 0.05\n",
    "    h = (mut + h)%2\n",
    "\n",
    "    n_pop.append(h)\n",
    "pop = np.array(n_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************GENERATION 0*****************************\n",
      "Best result:[[0.00369857]]..\n",
      "*****************************GENERATION 1*****************************\n",
      "Best result:[[0.0037377]]...\n",
      "*****************************GENERATION 2*****************************\n",
      "Best result:[[0.00385486]]..\n",
      "*****************************GENERATION 3*****************************\n",
      "Best result:[[0.00406617]]..\n",
      "*****************************GENERATION 4*****************************\n",
      "Best result:[[0.00406617]]..\n",
      "*****************************GENERATION 5*****************************\n",
      "Member 0: Loading data...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-0f5435007cc7>\", line 5, in <module>\n",
      "    fit.append(fitter(pop[i],i))\n",
      "  File \"<ipython-input-5-fa42930019d1>\", line 60, in fitter\n",
      "    x_train, x_test, y_train, y_test = getTVT_split(split)\n",
      "  File \"<ipython-input-4-bea0f40a19f7>\", line 2, in getTVT_split\n",
      "    df = getDf()\n",
      "  File \"<ipython-input-2-23b9b0caebaa>\", line 2, in getDf\n",
      "    df = pd.read_csv('train.csv')\n",
      "  File \"C:\\Users\\jonhe\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\", line 685, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\jonhe\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\", line 463, in _read\n",
      "    data = parser.read(nrows)\n",
      "  File \"C:\\Users\\jonhe\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\", line 1154, in read\n",
      "    ret = self._engine.read(nrows)\n",
      "  File \"C:\\Users\\jonhe\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\", line 2059, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 881, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas/_libs/parsers.pyx\", line 896, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 973, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1118, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"C:\\Users\\jonhe\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\dtypes\\common.py\", line 1743, in is_extension_array_dtype\n",
      "    def is_extension_array_dtype(arr_or_dtype):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "OSError: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: '<ipython-input-4-bea0f40a19f7>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\jonhe\\anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0f5435007cc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-fa42930019d1>\u001b[0m in \u001b[0;36mfitter\u001b[1;34m(gen, memb)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Member '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Loading data...'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTVT_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-bea0f40a19f7>\u001b[0m in \u001b[0;36mgetTVT_split\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetTVT_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'resp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-23b9b0caebaa>\u001b[0m in \u001b[0;36mgetDf\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m     \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for j in range(0,n_gen+1):\n",
    "    print('*****************************GENERATION '+str(j)+'*****************************')\n",
    "    fit = list()\n",
    "    for i in range(len(pop)):\n",
    "        fit.append(fitter(pop[i],i))\n",
    "    fit = np.array(fit)\n",
    "    tot_fit = np.append(fit.reshape(20,1),mez_fit,axis=0)\n",
    "    tot_pop = np.append(pop,mez_pop,axis=0)\n",
    "    pickle.dump(tot_pop,open('Generations/pop_'+str(j)+'.pkl','wb'))\n",
    "    pickle.dump(tot_fit,open('Generations/fit_'+str(j)+'.pkl','wb'))\n",
    "    \n",
    "    mez_pop = tot_pop[tot_fit[:,0].argsort()][-int(len(pop)/2):]\n",
    "    mez_fit = tot_fit[tot_fit[:,0].argsort()][-int(len(pop)/2):]\n",
    "    print('Best result:'+str(tot_fit[tot_fit[:,0].argsort()][-1:]))\n",
    "    n_pop = list()\n",
    "    for i in range(len(pop)):\n",
    "        p1 = rd.randint(0,int(len(pop)/2))\n",
    "        p2 = rd.randint(0,int(len(pop)/2))\n",
    "        h = rd.randint(0,2,adn,'int')\n",
    "        h = h.astype(bool)\n",
    "        p1 = mez_pop[p1]\n",
    "        p2 = mez_pop[p2]\n",
    "        p1 = p1*h\n",
    "        p2 = p2*np.invert(h)\n",
    "        h = p1+p2\n",
    "\n",
    "        mut = rd.rand(adn)\n",
    "        mut = mut < 0.02\n",
    "        h = (mut + h)%2\n",
    "\n",
    "        n_pop.append(h)\n",
    "    pop = np.array(n_pop)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "memb = 10\n",
    "gen = mez_pop[-1]\n",
    "split = round(int(np.array2string(gen[:15],separator='')[1:-1],2)/10**5 + 0.5,5)\n",
    "hid_layers = 21\n",
    "act_in = act[int(int(np.array2string(gen[15:22],separator='')[1:-1],2)/11)]\n",
    "nn_in = int(np.array2string(gen[22:29],separator='')[1:-1],2) + 1\n",
    "act_out = act[int(int(np.array2string(gen[29:36],separator='')[1:-1],2)/11)]\n",
    "\n",
    "nn_hid = np.zeros(21).astype('int')\n",
    "for i,j in zip(range(36,183,7),range(21)):\n",
    "    nn_hid[j] = int(np.array2string(gen[i:i+7],separator='')[1:-1],2)\n",
    "\n",
    "act_hid = np.zeros(21).astype('str')\n",
    "for i,j in zip(range(183,330,7),range(21)):\n",
    "    act_hid[j] = act[int(int(np.array2string(gen[i:i+7],separator='')[1:-1],2)/11)]\n",
    "\n",
    "sc_each = list()\n",
    "for i,j in zip(range(330,850,4),range(130)):\n",
    "    sc = int(np.array2string(gen[i:i+4],separator='')[1:-1],2)\n",
    "    if sc == 0:\n",
    "        scalerX = QuantileTransformer(output_distribution='normal',random_state=5)\n",
    "    elif sc == 1:\n",
    "        scalerX = QuantileTransformer(random_state=5)\n",
    "    elif sc == 2:\n",
    "        scalerX = MinMaxScaler()\n",
    "    elif sc == 3:\n",
    "        scalerX = StandardScaler()\n",
    "    elif sc == 4:\n",
    "        scalerX = StandardScaler(with_mean=True,with_std=False)\n",
    "    elif sc == 5:\n",
    "        scalerX = StandardScaler(with_mean=False,with_std=True)\n",
    "    elif sc == 6:\n",
    "        scalerX = StandardScaler(with_mean=False,with_std=False)\n",
    "    elif sc == 7:\n",
    "        scalerX = RobustScaler()\n",
    "    elif sc == 8:\n",
    "        scalerX = RobustScaler(with_centering=False,with_scaling=True)\n",
    "    elif sc == 9:\n",
    "        scalerX = RobustScaler(with_centering=True,with_scaling=False)\n",
    "    elif sc == 10:\n",
    "        scalerX = RobustScaler(with_centering=False,with_scaling=False)\n",
    "    elif sc == 11:\n",
    "        scalerX = PowerTransformer()\n",
    "    elif sc == 12:\n",
    "        scalerX = RobustScaler()\n",
    "    elif sc == 13:\n",
    "        scalerX = PowerTransformer(standardize=False)\n",
    "    elif sc == 14:\n",
    "        scalerX = MinMaxScaler()\n",
    "    elif sc == 15:\n",
    "        scalerX = MaxAbsScaler()\n",
    "    sc_each.append(scalerX)\n",
    "\n",
    "ls = losses[int(int(np.array2string(gen[850:857],separator='')[1:-1],2)/10)]\n",
    "opt = opts[int(np.array2string(gen[857:860],separator='')[1:-1],2)]\n",
    "\n",
    "if opt == 'adamT':\n",
    "    opt = optimizers.Adam(amsgrad=True)\n",
    "\n",
    "print('Member '+str(memb)+': '+'Loading data...',end='\\r',flush=True)\n",
    "x_train, x_test, y_train, y_test = getTVT_split(0.75)\n",
    "\n",
    "\n",
    "for i in range(130):\n",
    "    print('Member '+str(memb)+': '+'Scaling '+str(i)+'...',end='\\r',flush=True)\n",
    "    x_train[:,i+3:i+4] = sc_each[i].fit_transform(x_train[:,i+2:i+3])\n",
    "    x_test[:,i+3:i+4] = sc_each[i].transform(x_test[:,i+2:i+3])      \n",
    "\n",
    "model = Sequential()\n",
    "if act_in == '0':\n",
    "    model.add(Dense(nn_in,input_dim=(130)))\n",
    "else:\n",
    "    model.add(Dense(nn_in,input_dim=(130),activation=act_in))\n",
    "\n",
    "for i in range(21):\n",
    "    if nn_hid[i] == 0:\n",
    "        continue\n",
    "    elif act_hid[i] == '0':\n",
    "        model.add(Dense(nn_hid[i]))\n",
    "    else:\n",
    "        model.add(Dense(nn_hid[i],activation=act_hid[i]))\n",
    "\n",
    "if act_out == '0':\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "else:\n",
    "    model.add(Dense(y_train.shape[1],activation=act_out))\n",
    "\n",
    "model.compile(loss=ls,optimizer=opt)\n",
    "\n",
    "jumper = CustomJumper()\n",
    "eps = int(np.array2string(gen[860:865],separator='')[1:-1],2) + 1\n",
    "batch = int(np.array2string(gen[865:875],separator='')[1:-1],2) + 1\n",
    "print('Member '+str(memb)+': '+'Fitting model...',end='\\r',flush=True)\n",
    "error = False\n",
    "t = time()\n",
    "model.fit(x_train[:,3:],y_train,epochs=eps,batch_size=batch,verbose=0,callbacks=[jumper])\n",
    "\n",
    "print('Member '+str(memb)+': '+'Calculating LB...',end='\\r',flush=True)\n",
    "results = model.predict_classes(x_test[:,3:])\n",
    "\n",
    "LB_array = np.concatenate((x_test[:,:1],x_test[:,1:2]*x_test[:,2:3]*results),axis=1)\n",
    "K = (250/len(np.unique(LB_array[:,:1],axis=0)))**(1/2)\n",
    "LB_data = [np.sum(LB_array[:,1:][np.nonzero(LB_array[:,:1]==date)]) for date in np.unique(LB_array[:,:1])]\n",
    "t = np.sum(LB_data)/(np.sum(np.square(LB_data))**(1/2)) * K\n",
    "if(math.isnan(t)):\n",
    "    t = 0\n",
    "LB = min(max(t,0),6)*np.sum(LB_data)\n",
    "\n",
    "print(LB)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LB_array = np.concatenate((x_test[:,:1],x_test[:,1:2]*x_test[:,2:3]*y_test),axis=1)\n",
    "K = (250/len(np.unique(LB_array[:,:1],axis=0)))**(1/2)\n",
    "LB_data = [np.sum(LB_array[:,1:][np.nonzero(LB_array[:,:1]==date)]) for date in np.unique(LB_array[:,:1])]\n",
    "t = np.sum(LB_data)/(np.sum(np.square(LB_data))**(1/2)) * K\n",
    "if(math.isnan(t)):\n",
    "    t = 0\n",
    "LB = min(max(t,0),6)*np.sum(LB_data)\n",
    "\n",
    "print(LB)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "description = \"Train size: \"+str(0.8)+\"\\n\\n\"+\"Number of hidden layers: \"+str(hid_layers)+\"\\n\\n\"+\"Activation on input layer: \"+str(act_in)+\"\\n\\n\"+\"Number of neurons on input: \"+str(nn_in)+\"\\n\\n\"+\"Activation on ouput: \"+str(act_out)+\"\\n\\n\"+\"Number of neurons on hidden layers: \"+str(nn_hid)+\"\\n\\n\"+\"Activation on hidden layers: \"+str(act_hid)+\"\\n\\n\"+\"Scaler of each feature: \"+str(sc_each)+\"\\n\\n\"+\"Loss of the model: \"+str(ls)+\"\\n\\n\"+\"Optimizer of the model: \"+str(opt)+\"\\n\\n\"+\"Number of epochs in training: \"+str(eps)+\"\\n\\n\"+\"Batch size of training: \"+str(batch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle.dump(model,open('model_2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle.dump(sc_each,open('sc_each_2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle.dump(description,open('description_2.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
