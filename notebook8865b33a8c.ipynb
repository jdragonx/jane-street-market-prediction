{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-10T22:13:23.625254Z",
     "iopub.status.busy": "2021-01-10T22:13:23.624524Z",
     "iopub.status.idle": "2021-01-10T22:13:30.756797Z",
     "shell.execute_reply": "2021-01-10T22:13:30.755375Z"
    },
    "papermill": {
     "duration": 7.149226,
     "end_time": "2021-01-10T22:13:30.756953",
     "exception": false,
     "start_time": "2021-01-10T22:13:23.607727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import janestreet\n",
    "import cupy as cp\n",
    "import gc\n",
    "\n",
    "from time import time\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer, MaxAbsScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:13:30.792614Z",
     "iopub.status.busy": "2021-01-10T22:13:30.791601Z",
     "iopub.status.idle": "2021-01-10T22:13:30.795668Z",
     "shell.execute_reply": "2021-01-10T22:13:30.795065Z"
    },
    "papermill": {
     "duration": 0.029794,
     "end_time": "2021-01-10T22:13:30.795804",
     "exception": false,
     "start_time": "2021-01-10T22:13:30.766010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDf():\n",
    "    df = pd.read_csv('../input/jane-street-market-prediction/train.csv')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=['resp_1','resp_2','resp_3','resp_4','ts_id'])\n",
    "    \n",
    "    return df\n",
    "            \n",
    "def getTVT_split(split,mn):\n",
    "    global df\n",
    "    y = np.where(df['resp'] > mn,1,0).reshape(len(df),1)\n",
    "    resp = df['resp'].values.reshape(-1,1)\n",
    "    x = df.drop(columns=['resp']).values\n",
    "    date = x[:,:1]\n",
    "    weight = x[:,1:2]\n",
    "    x = x[:,2:]\n",
    "    \n",
    "    x_train, x_test = train_test_split(x,train_size=split,random_state=5)\n",
    "\n",
    "    y_train, y_test = train_test_split(y,train_size=split,random_state=5)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "def scaling(i):\n",
    "    global x_train, x_test, scalers\n",
    "    if(scalers[i]!=\"no\"):\n",
    "        x_train[:,i+0:i+1] = scalers[i].fit_transform(x_train[:,i+0:i+1])\n",
    "        x_test[:,i+0:i+1] = scalers[i].transform(x_test[:,i+0:i+1])\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:13:30.820968Z",
     "iopub.status.busy": "2021-01-10T22:13:30.820283Z",
     "iopub.status.idle": "2021-01-10T22:16:07.479975Z",
     "shell.execute_reply": "2021-01-10T22:16:07.478734Z"
    },
    "papermill": {
     "duration": 156.675707,
     "end_time": "2021-01-10T22:16:07.480117",
     "exception": false,
     "start_time": "2021-01-10T22:13:30.804410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = getDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:16:07.523746Z",
     "iopub.status.busy": "2021-01-10T22:16:07.513414Z",
     "iopub.status.idle": "2021-01-10T22:16:46.567574Z",
     "shell.execute_reply": "2021-01-10T22:16:46.570704Z"
    },
    "papermill": {
     "duration": 39.082973,
     "end_time": "2021-01-10T22:16:46.570912",
     "exception": false,
     "start_time": "2021-01-10T22:16:07.487939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 0.57165\n",
    "mn = 0\n",
    "hid_layers = 5\n",
    "act_in = 'elu'\n",
    "nn_in = 95\n",
    "act_out = 'linear'\n",
    "nn_hid = [72,54,60,6,83]\n",
    "act_hid = ['softplus','tanh','softsign','relu','selu']\n",
    "scalers = [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), 'no', StandardScaler(with_std=False),\n",
    "           StandardScaler(with_mean=False, with_std=False), StandardScaler(with_mean=False),\n",
    "           RobustScaler(), RobustScaler(with_centering=False), RobustScaler(), 'no', \n",
    "           StandardScaler(with_mean=False, with_std=False), 'no', QuantileTransformer(random_state=5),\n",
    "           MaxAbsScaler(), RobustScaler(with_centering=False), PowerTransformer(standardize=False),\n",
    "           StandardScaler(with_std=False), StandardScaler(with_std=False), 'no', MinMaxScaler(),\n",
    "           RobustScaler(with_scaling=False), PowerTransformer(),\n",
    "           StandardScaler(with_mean=False, with_std=False), RobustScaler(with_scaling=False), 'no',\n",
    "           QuantileTransformer(random_state=5), 'no', StandardScaler(with_mean=False),\n",
    "           RobustScaler(with_centering=False), StandardScaler(with_std=False),\n",
    "           StandardScaler(with_mean=False, with_std=False), StandardScaler(with_std=False),\n",
    "           StandardScaler(), QuantileTransformer(random_state=5), StandardScaler(),\n",
    "           QuantileTransformer(random_state=5), StandardScaler(with_mean=False, with_std=False),\n",
    "           RobustScaler(with_centering=False), MinMaxScaler(feature_range=(-1, 1)), PowerTransformer(),\n",
    "           PowerTransformer(standardize=False), QuantileTransformer(random_state=5),\n",
    "           RobustScaler(with_centering=False),\n",
    "           QuantileTransformer(output_distribution='normal', random_state=5),\n",
    "           MinMaxScaler(feature_range=(-1, 1)), StandardScaler(with_mean=False, with_std=False),\n",
    "           StandardScaler(), RobustScaler(), 'no', RobustScaler(with_scaling=False),\n",
    "           StandardScaler(with_std=False), RobustScaler(with_centering=False, with_scaling=False),\n",
    "           StandardScaler(with_mean=False, with_std=False),\n",
    "           RobustScaler(with_centering=False, with_scaling=False), MaxAbsScaler(), StandardScaler(),\n",
    "           MaxAbsScaler(), QuantileTransformer(random_state=5), MaxAbsScaler(),\n",
    "           QuantileTransformer(random_state=5), StandardScaler(with_mean=False),\n",
    "           StandardScaler(with_mean=False), RobustScaler(with_centering=False),\n",
    "           StandardScaler(with_mean=False), PowerTransformer(), RobustScaler(with_centering=False),\n",
    "           MinMaxScaler(feature_range=(-1, 1)),\n",
    "           QuantileTransformer(output_distribution='normal', random_state=5),\n",
    "           RobustScaler(with_centering=False), PowerTransformer(), MinMaxScaler(), RobustScaler(),\n",
    "           PowerTransformer()]\n",
    "n_features = len(scalers)\n",
    "ls = 'mean_squared_error'\n",
    "opt = 'adam'\n",
    "\n",
    "x_train, x_test, y_train, y_test = getTVT_split(split,mn)\n",
    "gc.collect()\n",
    "\n",
    "f_used = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
    "          1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
    "          1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
    "          0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, \n",
    "          1, 0]\n",
    "x_train = x_train[:,np.nonzero(f_used)][:,0]\n",
    "x_test = x_test[:,np.nonzero(f_used)][:,0]\n",
    "\n",
    "p = ThreadPool()\n",
    "p.map(scaling, range(n_features))\n",
    "p.close()\n",
    "p.join()\n",
    "gc.collect()\n",
    "eps = 144\n",
    "batch = 7208\n",
    "features_used = np.array(np.nonzero(f_used))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:16:46.614026Z",
     "iopub.status.busy": "2021-01-10T22:16:46.610473Z",
     "iopub.status.idle": "2021-01-10T22:18:09.698851Z",
     "shell.execute_reply": "2021-01-10T22:18:09.699335Z"
    },
    "papermill": {
     "duration": 83.115797,
     "end_time": "2021-01-10T22:18:09.699487",
     "exception": false,
     "start_time": "2021-01-10T22:16:46.583690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b57a6d6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(95,input_dim=(74),activation='elu'))\n",
    "model.add(Dense(72,activation='softplus'))\n",
    "model.add(Dense(54,activation='tanh'))\n",
    "model.add(Dense(60,activation='softsign'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(83,activation='selu'))\n",
    "model.add(Dense(y_train.shape[1],activation='linear'))\n",
    "\n",
    "model.compile(loss=ls,optimizer=opt)\n",
    "\n",
    "model.fit(x_train,y_train,epochs=eps,batch_size=batch,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:18:09.721299Z",
     "iopub.status.busy": "2021-01-10T22:18:09.720680Z",
     "iopub.status.idle": "2021-01-10T22:18:09.739892Z",
     "shell.execute_reply": "2021-01-10T22:18:09.740570Z"
    },
    "papermill": {
     "duration": 0.033322,
     "end_time": "2021-01-10T22:18:09.740834",
     "exception": false,
     "start_time": "2021-01-10T22:18:09.707512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 0.57165\n",
      "\n",
      "Lower limit for earning: 0\n",
      "\n",
      "Number of hiden layers: 5\n",
      "\n",
      "Activation on input layer: elu\n",
      "\n",
      "Number of neurons on input layer: 95\n",
      "\n",
      "Activation on output layer: linear\n",
      "\n",
      "Number of neurons on hidden layers: [72, 54, 60, 6, 83]\n",
      "\n",
      "Activation on hidden layers: ['softplus', 'tanh', 'softsign', 'relu', 'selu']\n",
      "\n",
      "Features used: [  1   2   4   5   6   7   8  13  17  18  19  22  23  25  26  27  29  32\n",
      "  34  35  37  38  40  41  43  44  50  52  54  57  58  61  62  63  64  68\n",
      "  69  70  73  75  77  79  81  82  84  87  88  91  92  93  94  97  99 100\n",
      " 101 102 104 105 106 107 108 111 114 115 116 117 118 120 122 123 124 126\n",
      " 127 128]\n",
      "\n",
      "Scalers of the features: [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), 'no', StandardScaler(with_std=False), StandardScaler(with_mean=False, with_std=False), StandardScaler(with_mean=False), RobustScaler(), RobustScaler(with_centering=False), RobustScaler(), 'no', StandardScaler(with_mean=False, with_std=False), 'no', QuantileTransformer(random_state=5), MaxAbsScaler(), RobustScaler(with_centering=False), PowerTransformer(standardize=False), StandardScaler(with_std=False), StandardScaler(with_std=False), 'no', MinMaxScaler(), RobustScaler(with_scaling=False), PowerTransformer(), StandardScaler(with_mean=False, with_std=False), RobustScaler(with_scaling=False), 'no', QuantileTransformer(random_state=5), 'no', StandardScaler(with_mean=False), RobustScaler(with_centering=False), StandardScaler(with_std=False), StandardScaler(with_mean=False, with_std=False), StandardScaler(with_std=False), StandardScaler(), QuantileTransformer(random_state=5), StandardScaler(), QuantileTransformer(random_state=5), StandardScaler(with_mean=False, with_std=False), RobustScaler(with_centering=False), MinMaxScaler(feature_range=(-1, 1)), PowerTransformer(), PowerTransformer(standardize=False), QuantileTransformer(random_state=5), RobustScaler(with_centering=False), QuantileTransformer(output_distribution='normal', random_state=5), MinMaxScaler(feature_range=(-1, 1)), StandardScaler(with_mean=False, with_std=False), StandardScaler(), RobustScaler(), 'no', RobustScaler(with_scaling=False), StandardScaler(with_std=False), RobustScaler(with_centering=False, with_scaling=False), StandardScaler(with_mean=False, with_std=False), RobustScaler(with_centering=False, with_scaling=False), MaxAbsScaler(), StandardScaler(), MaxAbsScaler(), QuantileTransformer(random_state=5), MaxAbsScaler(), QuantileTransformer(random_state=5), StandardScaler(with_mean=False), StandardScaler(with_mean=False), RobustScaler(with_centering=False), StandardScaler(with_mean=False), PowerTransformer(), RobustScaler(with_centering=False), MinMaxScaler(feature_range=(-1, 1)), QuantileTransformer(output_distribution='normal', random_state=5), RobustScaler(with_centering=False), PowerTransformer(), MinMaxScaler(), RobustScaler(), PowerTransformer()]\n",
      "\n",
      "Loss of the model: mean_squared_error\n",
      "\n",
      "Optimizer of the model: adam\n",
      "\n",
      "Epochs of training: 144\n",
      "\n",
      "Batch size: 7208\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: {}\\n\\nLower limit for earning: {}\\n\\nNumber of hiden layers: {}\\n\\nActivation on input layer: {}\\n\\nNumber of neurons on input layer: {}\\n\\nActivation on output layer: {}\\n\\nNumber of neurons on hidden layers: {}\\n\\nActivation on hidden layers: {}\\n\\nFeatures used: {}\\n\\nScalers of the features: {}\\n\\nLoss of the model: {}\\n\\nOptimizer of the model: {}\\n\\nEpochs of training: {}\\n\\nBatch size: {}\".format(split,\n",
    "mn,hid_layers,act_in,nn_in,act_out,nn_hid,act_hid,features_used,scalers,ls,opt,eps,batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:18:09.764259Z",
     "iopub.status.busy": "2021-01-10T22:18:09.762931Z",
     "iopub.status.idle": "2021-01-10T22:18:09.767533Z",
     "shell.execute_reply": "2021-01-10T22:18:09.766960Z"
    },
    "papermill": {
     "duration": 0.017905,
     "end_time": "2021-01-10T22:18:09.767635",
     "exception": false,
     "start_time": "2021-01-10T22:18:09.749730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = janestreet.make_env()\n",
    "iter_test = env.iter_test()\n",
    "test_df = 0\n",
    "p = ThreadPool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T22:18:09.792810Z",
     "iopub.status.busy": "2021-01-10T22:18:09.790970Z",
     "iopub.status.idle": "2021-01-10T22:18:09.793546Z",
     "shell.execute_reply": "2021-01-10T22:18:09.794061Z"
    },
    "papermill": {
     "duration": 0.017637,
     "end_time": "2021-01-10T22:18:09.794183",
     "exception": false,
     "start_time": "2021-01-10T22:18:09.776546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaler(i):\n",
    "    global test_df, scalers\n",
    "    if(scalers[i]!=\"no\"):\n",
    "        test_df[:,i+0:i+1] = scalers[i].transform(test_df[:,i+0:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-10T22:18:09.827080Z",
     "iopub.status.busy": "2021-01-10T22:18:09.826478Z",
     "iopub.status.idle": "2021-01-10T22:24:36.727296Z",
     "shell.execute_reply": "2021-01-10T22:24:36.726625Z"
    },
    "papermill": {
     "duration": 386.924072,
     "end_time": "2021-01-10T22:24:36.727417",
     "exception": false,
     "start_time": "2021-01-10T22:18:09.803345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    test_df = test_df.drop(columns=['date','weight','feature_0','feature_3','feature_9','feature_10',\n",
    "                                        'feature_11','feature_12','feature_14','feature_15','feature_16',\n",
    "                                        'feature_20','feature_21','feature_24','feature_28','feature_30',\n",
    "                                        'feature_31','feature_33','feature_36','feature_39','feature_42',\n",
    "                                        'feature_45','feature_46','feature_47','feature_48','feature_49',\n",
    "                                        'feature_51','feature_53','feature_55','feature_56','feature_59',\n",
    "                                        'feature_60','feature_65','feature_66','feature_67','feature_71',\n",
    "                                        'feature_72','feature_74','feature_76','feature_78','feature_80',\n",
    "                                        'feature_83','feature_85','feature_86','feature_89','feature_90',\n",
    "                                        'feature_95','feature_96','feature_98','feature_103','feature_109',\n",
    "                                        'feature_110','feature_112','feature_113','feature_119','feature_121',\n",
    "                                        'feature_125','feature_129']).values\n",
    "    if(np.isnan(test_df).any()):\n",
    "        sample_prediction_df.action = 0\n",
    "        env.predict(sample_prediction_df)\n",
    "    else:\n",
    "        p.map(scaler,range(74))\n",
    "        sample_prediction_df.action = int(model(test_df,training=False).numpy()[0,0] > 0.5)\n",
    "        env.predict(sample_prediction_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 678.94918,
   "end_time": "2021-01-10T22:24:38.204738",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-10T22:13:19.255558",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
